# <u>Central Limit</u>, <br>wai wha is thatch?

**Core Thing**: We know that the sample mean $\bar x$ varies from the population mean $\bar X$. So, the Central Limit Theorem considers a large number of random sample tests.

—

Now, each different sample taken from the population and the mean of them, if we plot those means — they will be ***normally distributed*** around the population mean $\bar X$.  

**The cool thing** is that, "even if the population itself is not normally distributed, the random samples' mean will *always be normally distributed.*

> 95% of all sample means, should fall in $2\sigma$ of the population mean. 

Actually, I have coded out this thing to check it: It goes like ↓ 
```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# generating bimodal data (non normal distribution)
x1 = np.random.randint(1, 5, 100)
x2 = np.random.randint(7, 15, 100)
x = np.concatenate([x1, x2])

# see how it looks
sns.kdeplot(x)
```
![Distribution](https://i.imgur.com/eS4G69F.png)
```python
x_mean = x.mean()
sns.kdeplot(x)
plt.vlines(x_mean, 0, .1, ls="--", color="pink", label="Population Mean")
plt.legend();
```
![Dist with mean](https://i.imgur.com/KfcWyTc.png)
```python
# Getting indices
length = np.arange(len(x))

# ↓ to store the sample means
means = []

# we will take 50 samples ↓ from the mean.
for th_sample in range(50):
    # Sample size will be 30 out of pop   ↓
    sample_idx = np.random.choice(length, 30)
    means.append(x[sample_idx].mean())

sns.kdeplot(x)
plt.vlines(x_mean, 0, .5, ls="--", color="pink", label="Population Mean")
sns.kdeplot(means)
```
![Final Dist](https://i.imgur.com/usFtk2b.png)
**Great!**
___
#### Okay, but why are they useful? 
From a to-the-point video of one of my favourite channels [StatQuest](https://youtu.be/YAlJCEDH2uY?t=319) he goes through the following explanation:

> When we don an experiment, we don't always know what distribution our data comes from. The distribution of the data can be anything. 
—
So, for that we have our *buddy* **CLT**. He says, "It doesn't matter what shape of your data is, I can always make it *normal*".<br>
AS we know the sample means are normally distributed, we don't need to worry about the shape of data. 
**We can use the mean's normal distributions for**:
\- *Confidence Intervals*
\- Do *t-tests*
\- *ANOVA*

Seems pretty useful, isn't it?


# Next up,
We will talk about the standard error. From now on, I feel like I should make seperate files for each concepts.