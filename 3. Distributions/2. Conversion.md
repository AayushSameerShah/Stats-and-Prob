# Conversion
Yes, the heading sound freaky, but the concept that we are about to learn does right that. 

**Motivation**: We live in the real world. We have another world called "A world of Numbers". In the world of numbers everything is symmetrical, perfect. But we are living in the real world where nothing is symmetrical in comparison to the numerical world.

But to carry out some insights, we have to make use of the numbers and for that ***we need to convert the real world data into numerical world data.***

The story is so dramatic, but here we will learn *how to convert Normal Distribution → Standard Normal distribution*.

What not reverse? It is because as the property of the normal dist says: "It can get any value for MMM and std". Now, we can't (shouldn't) directly work with that. *We need to convert Normal Dist to Standard Normal Dist*, where things are **more predictable** and **calculable**.

**Are we learning `StandardScaler`?**: Yes. In Machine Learning we often preprocess the data and standardize it so that our model can converge faster. Here, it is the same technique by which we will be able to convert the normal dist to standard normal. *(Aah, writing too much!)*.

Better to call: **"Standardization"**.

![Conversion](https://i.imgur.com/BDZNyBa.png)

- We will use the z-score
- With the z-score we can calculate the x value's percentile

**Percentile**: What percentage falls below this value. 
___
Now, just previously we saw a function to build the normal distribution which goes like:
#### $$f(x) = \frac{1}{\sqrt{2 \pi\sigma^2}} e^{\frac{-(x-\mu)^2}{2\sigma^2}}$$

But as the course says, we can directly use the z-scores. So, we should.

### What is Z-score?
The z-score is related with the z-table. 

- **Z-table**: Helps to interpret the z-score which results in the ***percentile*** or area under the curve which will always between 0 to 1.
- **Z-score**: It is a calculated real number which is the translated version of $x$ by the formulae: $z = \frac{x-\mu}{\sigma}$
- Then we will take *that* z-score and will check in the z-table for the percentile for that number $x$.

Now, see we have just seen the function $z = \frac{x-\mu}{\sigma}$. It is the function which we usually use in the pre-processing of the data in machine learning project. But we left the numbers converted as they are. We don't go to look for the percentile or the area under the curve there — because **we don't need the curve value there**.

In other terms:
> A z-table is the **Standard Normal Probabilities** which maps a particular z-score to the area under a normal distribution curve *to the left* of the score.

From `z-score` → we get `probability / percentile`
Which is `z` → `p`

We can also:
From `probability / percentile` → we get `z-score`
Which is `p` → `z`

In python:
```python
from scipy import stats

# Giving z score
z = 0.7
stats.norm.cdf(z)
0.758036347776927
# ↑ Returns the Probability / Percentile by looking
# in the z-table automatically

# Giving p
p = 0.758036347776927
stats.norm.ppf(z)
0.7
# ↑ Returns the  z-score from p
```

**Example:** 
- I am hiring people.
- I put a test.
- Person A scored 80.

Now, how am I gonna know how much well he performed. I need to know the population, the historical data on the same test.

Then I will,
- Convert the 80 score in z-score
- Get the `p value`.
- Then based on which I will determine to hire or not. 
- If that person has done exceptionally and has percentile / p value more than 90% then, I will hire otherwise take other steps.

Let's say that person has got the p-value: 0.9564 = 90.64%

![Area under curve](https://i.imgur.com/dBftu2v.png)

Having seen that, we can say that person A has left ~ 95% people behind. It is called: **"Area under the curve *to the left*"**.

Now, you can understand what the term *to the left means*.

# That's it!
In the next section, we will learn statistics. It is where we will apply what we have learnt till now to the real world situations. Sounds exciting.

See you there ∞